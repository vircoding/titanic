{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv(\"dataset/train.csv\")\n",
    "X_train = titanic.drop(['Survived'], axis=1)\n",
    "y_train = titanic['Survived'].values\n",
    "X_test = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "group1 = titanic[['Age', 'Pclass']].dropna().groupby(['Pclass']).median()\n",
    "\n",
    "class AgeImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        ret = X.copy()\n",
    "        for passenger in X[X['Age'].isnull()].index:\n",
    "            ret.loc[passenger, 'Age'] = group1.loc[X.loc[passenger, 'Pclass'], 'Age']\n",
    "        return ret\n",
    "\n",
    "titanic_age_imputer = AgeImputer()\n",
    "titanic_age_imputed = titanic_age_imputer.transform(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = titanic_age_imputed.loc[:, ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "cat = titanic_age_imputed.loc[:, ['Sex', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "num_imputed = num_imputer.fit_transform(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_age_bucket = pd.DataFrame(num_imputer.fit_transform(titanic[['Survived', 'Age']]), columns=['Survived', 'Age'])\n",
    "titanic_age_bucket['AgeBucket'] = titanic_age_bucket['Age'] // 15 * 15\n",
    "age_bucket = titanic_age_bucket[\n",
    "    ['Survived', 'AgeBucket']].groupby(['AgeBucket']).mean()\n",
    "\n",
    "class AttributeAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        sibsp_parch = X[:, 2] + X[:, 3]\n",
    "        age_surv_rate = [age_bucket.loc[X[i, 1] // 15 * 15] for i in range(len(X))]\n",
    "        return np.c_[np.delete(X, [1, 2, 3], axis=1), sibsp_parch, age_surv_rate]\n",
    "\n",
    "num_attribs_adder = AttributeAdder()\n",
    "num_attribs_added = num_attribs_adder.fit_transform(num_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_scaler = StandardScaler()\n",
    "num_scaled = num_scaler.fit_transform(num_attribs_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='median')), \n",
    "    ('num_attribs_adder', AttributeAdder()), \n",
    "    ('num_scaler', StandardScaler()), \n",
    "    ])\n",
    "\n",
    "num_preprocessed = num_pipeline.fit_transform(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "cat_imputer = MostFrequentImputer()\n",
    "cat_imputed = cat_imputer.fit_transform(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "cat_encoded = cat_encoder.fit_transform(cat_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('cat_imputer', MostFrequentImputer()), \n",
    "    ('cat_encoder', OneHotEncoder(sparse=False)), \n",
    "    ])\n",
    "\n",
    "cat_preprocess = cat_pipeline.fit_transform(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_attribs = ['Sex', 'Embarked']\n",
    "\n",
    "num_cat_pipeline = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, num_attribs), \n",
    "    ('cat_pipeline', cat_pipeline, cat_attribs), \n",
    "    ])\n",
    "\n",
    "manual_preprocessed = np.c_[num_scaled, cat_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    ('data_age_imputer', AgeImputer()), \n",
    "    ('num_cat_pipeline', num_cat_pipeline), \n",
    "    ])\n",
    "\n",
    "X_train_preprocessed = preprocess_pipeline.fit_transform(X_train)\n",
    "\n",
    "assert np.allclose(manual_preprocessed, X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_clf = SVC(gamma='auto')\n",
    "svm_scores = cross_val_score(svm_clf, X_train_preprocessed, y_train,\n",
    "                             cv=10, scoring='accuracy')\n",
    "print(\"svm_score: \", svm_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100)\n",
    "forest_scores = cross_val_score(forest_clf, X_train_preprocessed, y_train, \n",
    "                                cv=10, scoring='accuracy')\n",
    "print(\"forest_score: \", forest_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], \n",
    "          'C': [10., 30., 100., 300.]},\n",
    "        {'kernel': ['rbf'], \n",
    "          'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "          'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "        ]\n",
    "\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=5, \n",
    "                            scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    ('preprocess_pipeline', preprocess_pipeline), \n",
    "    ('classifier', grid_search.best_estimator_) , \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "joblib.dump(full_pipeline, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"model.pkl\")\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def write_csv(predictions, name='submit.csv'):\n",
    "    dframe = pd.DataFrame(np.array([list(range(892, 892 + 418)), predictions]).T, \n",
    "                          columns=['PassengerId', 'Survived'])\n",
    "    csv_path = os.path.join(\"data\", name)\n",
    "    dframe.to_csv(csv_path, index=False)\n",
    "\n",
    "write_csv(predictions, \"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
